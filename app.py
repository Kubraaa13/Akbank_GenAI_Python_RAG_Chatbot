import streamlit as st
import os

# --- SADECE IMPORT'LAR EN ÃœSTTE OLMALI ---
# DiÄŸer tÃ¼m Streamlit komutlarÄ± bundan sonra gelir

# SET_PAGE_CONFIG MUTLAKA Ä°LK STREAMLIT KOMUTU OLMALIDIR
st.set_page_config(
    page_title="Akbank RAG Python Chatbot ğŸ", 
    layout="wide", 
    initial_sidebar_state="expanded" 
)

# RAG Ã‡EKÄ°RDEK IMPORTLARI (DiÄŸer importlar)
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA

# --- AYARLAR VE GÃœVENLÄ°K ---
# load_dotenv, set_page_config'den SONRA Ã§alÄ±ÅŸabilir
LLM_MODEL = "gemini-2.5-flash"
EMBEDDING_MODEL = "models/text-embedding-004"
DATA_FILE_PATH = "python_kod_aciklamalari.txt"


# --- RAG FONKSÄ°YONLARI ---

def load_and_chunk_data(file_path):
    """Veri dosyasÄ±nÄ± yÃ¼kler ve RAG iÃ§in parÃ§alara bÃ¶ler."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            raw_text = f.read()
    except FileNotFoundError:
        st.error(f"HATA: Veri dosyasÄ± ({file_path}) bulunamadÄ±. LÃ¼tfen kontrol edin.")
        return []

    text_splitter = CharacterTextSplitter(
        separator="\nKOD-", 
        chunk_size=3000,
        chunk_overlap=0 
    )
    texts = text_splitter.split_text(raw_text)
    return [f"KOD-{t.strip()}" for t in texts if t.strip()]

@st.cache_resource 
def create_rag_chain():
    """RAG zincirini kurar (Veri yÃ¼kleme, Embedding ve ChromaDB)."""
    
    # ------------------------------------------------------------------
    if "GOOGLE_API_KEY" not in st.secrets:
        st.error("LÃ¼tfen Streamlit ayarlarÄ±nda 'Secrets' bÃ¶lÃ¼mÃ¼ne GOOGLE_API_KEY'i ekleyin.")
        st.warning("Ã–rnek: GOOGLE_API_KEY=\"AIzaSy...\"")
        return None
    
    # API AnahtarÄ±nÄ± al ve os.environ'a yerleÅŸtir. Langchain bunu buradan okur.
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"] 
    # ------------------------------------------------------------------

    knowledge_base = load_and_chunk_data(DATA_FILE_PATH)
    if not knowledge_base:
        return None

    # VektÃ¶rleÅŸtirme (Embedding)
    try:
        embedding_model = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
        vectorstore = Chroma.from_texts(
            texts=knowledge_base, 
            embedding=embedding_model, 
            persist_directory="./chroma_db"
        )
    except Exception as e:
        st.error(f"RAG Kurulum HatasÄ±: API eriÅŸiminde sorun oluÅŸtu. Detay: {e}")
        st.warning("LÃ¼tfen API kotanÄ±zÄ± kontrol edin.")
        return None

    # LLM'i TanÄ±mlama ve Zinciri OluÅŸturma
    llm = ChatGoogleGenerativeAI(
        model=LLM_MODEL, 
        temperature=0.2,
        convert_system_message_to_human=True 
    )
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        chain_type="stuff", 
        retriever=vectorstore.as_retriever()
    )
    return qa_chain


# --- STREAMLIT WEB ARAYÃœZÃœ ANA FONKSÄ°YONU ---

def main():
    st.title("ğŸ Python Kod Rehberi Chatbot")
    st.subheader("Gemini Destekli RAG UygulamasÄ±")
    st.markdown("---")

    qa_chain = create_rag_chain()

    if qa_chain is None:
        st.warning("Chatbot baÅŸlatÄ±lamadÄ±. LÃ¼tfen yukarÄ±daki hatalarÄ± giderin.")
        return

    st.success("Chatbot KullanÄ±ma HazÄ±r!")

    user_query = st.text_input("Python kodlarÄ± hakkÄ±nda bir soru sorun (Ã–rn: 'SÄ±nÄ±f nasÄ±l tanÄ±mlanÄ±r?')")

    if user_query:
        with st.spinner("Cevap Ãœretiliyor..."):
            try:
                result = qa_chain.invoke({"query": user_query})
                response_text = result.get('result', 'Cevap alÄ±namadÄ±.')

                st.markdown("### ğŸ¤– Bot CevabÄ±:")
                st.markdown(response_text) 
                
            except Exception as e:
                st.error(f"Sorgulama SÄ±rasÄ±nda Hata: API'ye baÄŸlanÄ±lamadÄ± veya kod Ã§alÄ±ÅŸmadÄ±. Detay: {e}")

if __name__ == '__main__':
    main()